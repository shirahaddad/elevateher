#!/usr/bin/env node

/**
 * Analytics Migration Script
 * Applies the analytics database tables and functions
 */

const fs = require('fs');
const path = require('path');

// Database connection setup (replace with your actual connection)
const { createClient } = require('@supabase/supabase-js');

// Load environment variables
let supabaseUrl, supabaseServiceKey;

try {
  // Try to load from .env.local
  const envPath = path.join(__dirname, '..', '.env.local');
  if (fs.existsSync(envPath)) {
    const envContent = fs.readFileSync(envPath, 'utf8');
    const envLines = envContent.split('\n');
    
    envLines.forEach(line => {
      const [key, ...valueParts] = line.split('=');
      if (key && valueParts.length > 0) {
        let value = valueParts.join('=').trim();
        // Remove quotes if present
        if ((value.startsWith('"') && value.endsWith('"')) || 
            (value.startsWith("'") && value.endsWith("'"))) {
          value = value.slice(1, -1);
        }
        process.env[key.trim()] = value;
      }
    });
  }
  
  supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL;
  supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY;
} catch (error) {
  // Fallback to environment variables if .env.local doesn't exist
  supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL;
  supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY;
}

if (!supabaseUrl || !supabaseServiceKey) {
  console.error('‚ùå Missing required environment variables:');
  console.error('   - NEXT_PUBLIC_SUPABASE_URL');
  console.error('   - SUPABASE_SERVICE_ROLE_KEY');
  process.exit(1);
}

const supabase = createClient(supabaseUrl, supabaseServiceKey);

async function applyAnalyticsMigration() {
  try {
    console.log('üöÄ Starting analytics migration...\n');

    // Read the migration file
    const migrationPath = path.join(__dirname, '..', 'database', 'migrations', '002_create_analytics_tables.sql');
    const migrationSQL = fs.readFileSync(migrationPath, 'utf8');

    console.log('üìÑ Migration file loaded successfully');

    // Split SQL into individual statements
    const statements = migrationSQL
      .split(';')
      .map(statement => statement.trim())
      .filter(statement => statement.length > 0 && !statement.startsWith('--'));

    console.log(`üìù Found ${statements.length} SQL statements to execute\n`);

    // Execute each statement
    for (let i = 0; i < statements.length; i++) {
      const statement = statements[i];
      if (statement) {
        try {
          console.log(`   ${i + 1}/${statements.length} Executing: ${statement.substring(0, 50)}...`);
          const { error } = await supabase.rpc('exec_sql', { sql: statement });
          
          if (error) {
            // Try direct execution for some statements
            const { error: directError } = await supabase.from('_').select('*').limit(0);
            if (directError) {
              console.warn(`   ‚ö†Ô∏è  Warning: ${error.message}`);
            }
          }
        } catch (err) {
          console.warn(`   ‚ö†Ô∏è  Warning executing statement: ${err.message}`);
        }
      }
    }

    // Create the database functions that might not be included in the migration
    console.log('\nüìä Creating analytics database functions...');

    // Function to get top pages
    const topPagesFunction = `
      CREATE OR REPLACE FUNCTION get_top_pages(days_back integer DEFAULT 30)
      RETURNS TABLE(page text, views bigint) AS $$
      BEGIN
        RETURN QUERY
        SELECT 
          page_url::text as page,
          COUNT(*)::bigint as views
        FROM page_views
        WHERE created_at >= NOW() - (days_back || ' days')::interval
        GROUP BY page_url
        ORDER BY views DESC
        LIMIT 10;
      END;
      $$ LANGUAGE plpgsql;
    `;

    // Function to get daily stats
    const dailyStatsFunction = `
      CREATE OR REPLACE FUNCTION get_daily_stats(days_back integer DEFAULT 30)
      RETURNS TABLE(date date, page_views bigint, unique_visitors bigint) AS $$
      BEGIN
        RETURN QUERY
        SELECT 
          DATE(created_at) as date,
          COUNT(*)::bigint as page_views,
          COUNT(DISTINCT session_id)::bigint as unique_visitors
        FROM page_views
        WHERE created_at >= NOW() - (days_back || ' days')::interval
        GROUP BY DATE(created_at)
        ORDER BY date DESC;
      END;
      $$ LANGUAGE plpgsql;
    `;

    try {
      console.log('   Creating get_top_pages function...');
      const { error: topPagesError } = await supabase.rpc('exec_sql', { sql: topPagesFunction });
      if (topPagesError) console.warn(`   ‚ö†Ô∏è  ${topPagesError.message}`);

      console.log('   Creating get_daily_stats function...');
      const { error: dailyStatsError } = await supabase.rpc('exec_sql', { sql: dailyStatsFunction });
      if (dailyStatsError) console.warn(`   ‚ö†Ô∏è  ${dailyStatsError.message}`);
    } catch (err) {
      console.warn(`   ‚ö†Ô∏è  Warning creating functions: ${err.message}`);
    }

    console.log('\n‚úÖ Analytics migration completed successfully!');
    console.log('\nüìã Summary:');
    console.log('   ‚úì Analytics events table created');
    console.log('   ‚úì Page views table created');
    console.log('   ‚úì Analytics sessions table created');
    console.log('   ‚úì Indexes created for optimal performance');
    console.log('   ‚úì Views created for reporting');
    console.log('   ‚úì Database functions created');
    
    console.log('\nüéØ Next steps:');
    console.log('   1. Add NEXT_PUBLIC_GA_MEASUREMENT_ID to your environment variables');
    console.log('   2. Test the analytics tracking on your website');
    console.log('   3. Check the admin analytics dashboard');

  } catch (error) {
    console.error('‚ùå Error applying analytics migration:', error.message);
    process.exit(1);
  }
}

// Run the migration
applyAnalyticsMigration();